# lambda = 1/15
# We are asked for P(55<S4<=60), with S4 = Time of the 4th goal ~ Gamma(4, lambda)
pgamma(60, 4, 1/15) - pgamma(55, 4, 1/15)
# Could be done as P(N55 =3, N60 - N55 <=1) = P(N55 = 3)*P(N5 >=1)
dpois(3, 55*1/15)*(1- ppois(1, 5*1/15))
# Could be done as P(N55 =3, N60 - N55 <=1) = P(N55 = 3)*P(N5 >=1)
dpois(3, 55*1/15)*(1- ppois(0, 5*1/15))
# Could be done as P(N55 =3, N60 - N55 <=1) = P(N55 = 3)*P(N5 >=1) = P(N55 = 3)*(1-P(N5 < 1))
# = P(N55 = 3)*(1-P(N5 = 0))
dpois(3, 55*1/15)*(1- ppois(0, 6*1/15))
# Could be done as P(N55 =3, N60 - N55 <=1) = P(N55 = 3)*P(N5 >=1) = P(N55 = 3)*(1-P(N5 < 1))
# = P(N55 = 3)*(1-P(N5 = 0))
dpois(3, 55*1/15)*(1- dpois(0, 6*1/15))
# Could be done as P(N55 =3, N60 - N55 <=1) = P(N55 = 3)*P(N5 >=1) = P(N55 = 3)*(1-P(N5 < 1))
# = P(N55 = 3)*(1-P(N5 = 0))
dpois(3, 55*1/15)*(1- dpois(1, 6*1/15))
# Could be done as P(N55 =3, N60 - N55 <=1) = P(N55 = 3)*P(N5 >=1) = P(N55 = 3)*(1-P(N5 < 1))
# = P(N55 = 3)*(1-P(N5 = 0))
dpois(3, 55*1/15)*(1- ppois(1, 6*1/15))
# (a) In a 60-min. game, find the prob. that a 4th goal occurs in the last 5 min
# (b) If at least 3 goals are scored in a game, what is the mean time of the 3rd goal?
# ---
# (a)
# lambda = 1/15
# We are asked for P(55<S4<=60), with S4 = Time of the 4th goal ~ Gamma(4, lambda)
pgamma(60, 4, 1/15) - pgamma(55, 4, 1/15)
integrate(
function(t) t * (lambda^shape * t^(shape-1) * exp(-lambda * t) / factorial(shape-1)),
lower = 0, upper = 60
)$value
lambda = 1/15
integrate(
function(t) t * (lambda^shape * t^(shape-1) * exp(-lambda * t) / factorial(shape-1)),
lower = 0, upper = 60
)$value
shape = 3
integrate(
function(t) t * (lambda^shape * t^(shape-1) * exp(-lambda * t) / factorial(shape-1)),
lower = 0, upper = 60
)$value
integral/PS3_60
integral <- 25.49384
integral/PS3_60
PS3_60 <- pgamma(60, 3, 1/15)
integral <- 25.49384
integral/PS3_60
+ )$value
integral <- integrate(
+     function(t) t * (lambda^shape * t^(shape-1) * exp(-lambda * t) / factorial(shape-1)),
+     lower = 0, upper = 60)$value
integral <- integrate(
function(t) t * (lambda^shape * t^(shape-1) * exp(-lambda * t) / factorial(shape-1)),
lower = 0, upper = 60)$value
integral/PS3_60
# Assume births occur on a maternity ward as a Poisson process w/ rate
# 2 births/h. Each birth is male or female indep. w/ prob. p = 0.519 and
# 1 âˆ’p
# (a) On an 8-h shift, what is the mean and standard dev. of the
# number of female births?
# (b) Find the prob. that only girls were born between 2 and 5 pm
# ---
# lambda_total = 2, lambda_male = 2*p, lambda_fem = 2*(1-p)
# N_t = Total counting process, M_t = Male counting process, F_t = Female counting process
# We are asked for F_8~Pois(8*lambda_fem)
lambda = 2
p=0.519
lambda_f = 2*(1-p)
# E(F_8) = 8*2*(1-p)
8*2*(1-p)
# Sd(F_8) = sqrt(Var(F_8)) = sqrt(8*2*(1-p))
sqrt(8*2*(1-p))
# (b) We are asked for P(M_3 = 0, F_3 > 0) = [Indip thin processes] = P(M_3 = 0)*P(F_3 > 0)
dpois(0,3*2*p)*(1-ppois(0, 3*2*(1-p)))
pgamma(3, 60, 20)-pgamma(2.9, 60, 20)
# (b) We are asked for P(2.9<=S60<=3|N3 = 60), U_{(60)} = max U_i order statistic of U[0,3]
# P(2.9<=S60<=3|N3 = 60) = P(2.9<=U_{(60)}<=3) = P(2.9<=U_{(60)}) = 1- P(max U_i<2.9) =
# 1- (P(U[0,3] <2.9))^60
1- (punif(2.9, 0,3))^60
## EXERCISE 6
# Students arrive at a cafeteria as a nonhomogeneous Poisson process. The
# arrival rate grows linearly from 100 to 200 students/h between 11am and noon.
# The rate stays constant for the next two hours, and then decreases linearly to
# 100 from 2 to 3pm. Find the prob. that at least 400 people arrive in the
# cafeteria between 11:30am and 1:30pm
# ---
# The function is constructed in theory
# We are asked for P(N2.5 - N0.5 > 400)
# The expectation of N2.5 - N0.5 is int_0.5^2-5 lambda(t)dt =
100+50-100*0.5-50*(0.5)^2 + 200*1.5
## EXERCISE 6
# Students arrive at a cafeteria as a nonhomogeneous Poisson process. The
# arrival rate grows linearly from 100 to 200 students/h between 11am and noon.
# The rate stays constant for the next two hours, and then decreases linearly to
# 100 from 2 to 3pm. Find the prob. that at least 400 people arrive in the
# cafeteria between 11:30am and 1:30pm
# ---
# The function is constructed in theory
# We are asked for P(N2.5 - N0.5 > 400)
# The expectation of N2.5 - N0.5 is int_0.5^2-5 lambda(t)dt =
lambda = 100+50-100*0.5-50*(0.5)^2 + 200*1.5
# So N2.5 - N0.5~Pois(lambda)
1-ppois(400, lambda)
# So N2.5 - N0.5~Pois(lambda)
1-ppois(399, lambda)
##### Matrix powers ###############################
# matrixpower(mat,k) mat^k
#
matrixpower <- function(mat,k) {
if (k == 0) return (diag(dim(mat)[1]))
if (k == 1) return(mat)
if (k > 1) return( mat %*% matrixpower(mat, k-1))
}
markov <- function(init,mat,n,labels) {
if (missing(labels)) labels <- 1:length(init)
simlist <- numeric(n+1)
states <- 1:length(init)
simlist[1] <- sample(states,1,prob=init)
for (i in 2:(n+1))
{ simlist[i] <- sample(states,1,prob=mat[simlist[i-1],]) }
labels[simlist]
}
P = matrix(c(
0.2, 0.6, 0.2,
0.1, 0.8, 0.1,
0.1, 0.6, 0.3), byrow = TRUE)
P
P = matrix(c(
0.2, 0.6, 0.2,
0.1, 0.8, 0.1,
0.1, 0.6, 0.3), nrow = 3)
P
P = matrix(c(
0.2, 0.6, 0.2,
0.1, 0.8, 0.1,
0.1, 0.6, 0.3), nrow = 3, byroe = TRUE)
P = matrix(c(
0.2, 0.6, 0.2,
0.1, 0.8, 0.1,
0.1, 0.6, 0.3), nrow = 3, byrow = TRUE)
P
p2 = p0%*%matrixpower(P,2)
# ConsideraMarkovchainmodelwithstatesS={1,2,3}fordailyweather
# evolutioninacity,w/1=rain,2=snowand3=clear,andwithtrans.probab.
#
#           0.2 0.6 0.2
#   P  =    0.1 0.8 0.1
#           0.1 0.6 0.3
#
# Supposethat,fortomorrow,a50%-50%chanceofrainandsnowis
# predicted.Findtheprobabilitythat itwillsnow2dayslater
# ---
p0 = (0.5,0.5,0)
p2 = p0%*%matrixpower(P,2)
# ConsideraMarkovchainmodelwithstatesS={1,2,3}fordailyweather
# evolutioninacity,w/1=rain,2=snowand3=clear,andwithtrans.probab.
#
#           0.2 0.6 0.2
#   P  =    0.1 0.8 0.1
#           0.1 0.6 0.3
#
# Supposethat,fortomorrow,a50%-50%chanceofrainandsnowis
# predicted.Findtheprobabilitythat itwillsnow2dayslater
# ---
p0 = (0.5,0.5,0)
# ConsideraMarkovchainmodelwithstatesS={1,2,3}fordailyweather
# evolutioninacity,w/1=rain,2=snowand3=clear,andwithtrans.probab.
#
#           0.2 0.6 0.2
#   P  =    0.1 0.8 0.1
#           0.1 0.6 0.3
#
# Supposethat,fortomorrow,a50%-50%chanceofrainandsnowis
# predicted.Findtheprobabilitythat itwillsnow2dayslater
# ---
p0 = c(0.5,0.5,0)
p2 = p0%*%matrixpower(P,2)
p2
p0 = rep(0.25,4)
p0
P = matrix(c(
0.0, 0.5, 0.5, 0.0,
0.5, 0.0, 0.5, 0.0,
0.4, 0.0, 0.0, 0.6,
0.0, 0.2, 0.6, 0.2), nrow = 4, byrow = TRUE)
P
# P{X3=4,X5=4,X6=3}=p(3)_4 p(2)_44 p_43
p0%*%matrixpower(P,3)[4]*matrixpower(P,2)[4,4]*P[4,3]
# P{X3=4,X5=4,X6=3}=p(3)_4 p(2)_44 p_43
(p0%*%matrixpower(P,3))[4]*matrixpower(P,2)[4,4]*P[4,3]
#0.4 * 0.6 *0.248
0.4 * 0.6 *0.248
P[4,3]
matrixpower(P,2)[4,4]
p0%*%matrixpower(P,3))[4]
(p0%*%matrixpower(P,3))[4]
library(readxl)
num_vars <- c("ref.hip.zona", "antig", "Poca_limp", "PM10", "Pobl.0_14_div_Poblac.Total" ,   "PoblJubilada_div_Poblac.Total", "Inmigrantes.porc", "Pocas_zonas")
# execute
data <- read_excel("Data/data_train.xlsx")
setwd("C:/Users/Nicolas/Desktop/GitHub/uc3m_regression_competition")
# execute
data <- read_excel("Data/data_train.xlsx")
data_num = data[, c('precio.house.m2', num_vars)]
data_num$y = log(data_num$precio.house.m2)
data_num$precio.house.m2<- NULL
predictors <- setdiff(num_vars, "y")
gam_formula <- as.formula(
paste("y ~", paste(c(paste0("s(", predictors, ", bs='ps', k = 40, m = 3)"),cat_vars), collapse = " + "))
)
cat_vars <- NULL
gam_formula <- as.formula(
paste("y ~", paste(c(paste0("s(", predictors, ", bs='ps', k = 40, m = 3)"),cat_vars), collapse = " + "))
)
gam_model <- gam(gam_formula, data = data_train)
## Fit P-Splines + categorical (GAM) Model
library(mgcv)
gam_model <- gam(gam_formula, data = data_num)
gam_model
summary(gam_model)
predictors = setdiff(predictors, c('PM10','Inmigrantes.porc'))
gam_model <- gam(gam_formula, data = data_num)
summary(gam_model)
gam_formula <- as.formula(
paste("y ~", paste(c(paste0("s(", predictors, ", bs='ps', k = 40, m = 3)"),cat_vars), collapse = " + "))
)
gam_model <- gam(gam_formula, data = data_num)
summary(gam_model)
library(readxl)
library(leaps)
library(caret)
library(groupdata2)
library(car)
library(dplyr)
library(mgcv)
library(MASS)
library(geosphere)
## Check Multicoliniearity -----------------------------------------------------
check_multicollinearity <- function(model, data) {
# Identify numerical and categorical variables
predictors <- labels(terms(model)) # Variables used in the model
data <- data[predictors]
num_id <- sapply(data, is.numeric)
num_vars <- names(data)[num_id]
cat_vars <- names(data)[!num_id]
# Model Matrix
X <- data[,num_vars]
R <- cor(X)
# Calculate condition number using kappa
condition_number <- kappa(R, exact = TRUE)
# Calculating VIF values using the car package
vif_values <- tryCatch({
vif(model)
}, error = function(e) {
warning("Could not calculate VIF due to collinearity issues.")
return(NA)
})
# Generate warnings if there are significant problems
if (condition_number > 30) {
warning("High condition number detected, indicating potential multicollinearity issues.")
}
if (any(vif_values > 10, na.rm = TRUE)) {
warning("VIF values greater than 10 detected, indicating potential multicollinearity issues.")
}
# Give out diagnostics
cat("=== Multicollinearity Diagnostics ===\n")
if (is.na(condition_number)) {
cat("Serious issues detected in the condition number.\n")
} else {
cat("Condition Number:", round(condition_number, 2), "\n")
}
cat("VIF Values:\n")
if (all(is.na(vif_values))) {
cat("VIF values could not be calculated due to collinearity.\n")
} else {
print(vif_values)
}
# Return results
return(list(
condition_number = condition_number,
vif_values = vif_values
))
}
### K-fold CV ------------------------------------------------------------------
k_fold <- function(data, k, cat_vars = c("tipo.casa"), obj_var = "y") {
# Create a k-fold partition with balanced cat_vars and which
# tries to minimize similar values in obj_var
folded_data <- fold(data,
k = k,
cat_col = cat_vars,
num_col = obj_var)
# It adds a new variable, .folds, which assigns a value 1 to k to each
# instance, dividing them by folds
# Return the new dataset
return(folded_data)
}
#### WARNING --- IN PROGRESS
### Loop to find a comprehensively balanced seed for the k-fold
seed <- 1
mix <- 1000000
k = 4
Tot_table <- list()
n <- 736
for (var in cat_vars){
Tot_table[[as.name(var)]] = table(data[[as.name(var)]])/n
}
for (i in 1:2000){
set.seed(i)
folded_data <- fold(data_train,
k = k,
cat_col = "tipo.casa",
num_col = "y")
mix_aux <- 0
for (j in 1:k){
temp_indexes <- which(folded_data$.folds == j)
ll <- length(temp_indexes)
for(var in cat_vars){
mix_aux= mix_aux + sum(abs(table(data_train[[as.name(var)]][which(folded_data$.folds == j)])/ll - Tot_table[[as.name(var)]]))
}
}
print(i)
print(mix_aux)
if (mix_aux < mix){
seed <- i
mix <- mix_aux
}
}
print(seed) # Up until 2000 ---> 416 is the best (k=4) 44 is the best seed (k=10)
for (j in 1:k){
print(paste(j, "- Fold   ==================================================="))
for(var in cat_vars){
print(paste(var,"----------------------------------------------------------"))
print(table(data_train[[as.name(var)]][which(folded_data$.folds == j)])/ll)
print(Tot_table[[as.name(var)]])
}
}
k_fold <- function(data, k=4, cat_vars = c("tipo.casa"), obj_var = "y") {
# Set the previously studied best seed (balance-wise)
set.seed(416)
# Create a k-fold partition with balanced cat_vars and which
# tries to minimize similar values in obj_var
folded_data <- fold(data,
k = k,
cat_col = cat_vars,
num_col = obj_var)
# It adds a new variable, .folds, which assigns a value 1 to k to each
# instance, dividing them by folds
# Return the new dataset
return(folded_data)
}
fit_linear_model = function(formula, data_train){
model = lm(formula,data = data_train)
return(model)
}
k_fold_cv_linear_model <- function(model_formula,
data_train,
k=4){
cat("=== Running k_fold Cross Validation --- lm === \n")
# Create the K-fold partition
folded_data <- k_fold(data_train,k)$.folds
# Initialize a vector to store each fold's rsme
cv_rmse <- numeric(k)
# Initialize a vector to store each fold's Rsq_adj
cv_rsq_adj <- numeric(k)
for (i in 1:k){
# Create the fold's test/train split
temp_train <- data_train[which(folded_data!=i),]
temp_test <- data_train[which(folded_data==i),]
# Fit the model and make predictions
temp_model <- fit_linear_model(model_formula, temp_train)
temp_predictions <- predict(temp_model, newdata = temp_test)
## Calculate error metrics and store them
# rsq adj
n_test = nrow(temp_test)
num_predictors = length(coefficients(temp_model))
SSE = sum((exp(temp_test$y) - exp(temp_predictions))^2)
SST = sum((mean(exp(temp_test$y)) - exp(temp_test$y))^2)
cv_rsq_adj[i] = 1 - (SSE/(n_test-num_predictors))/(SST/(n_test-1))
# rmse
cv_rmse[i] <- sqrt(SSE/n_test)
}
# Return the vector with rmse for each k-fold
return(list(cv_rmse=cv_rmse,
mean_cv_rmse = mean(cv_rmse),
cv_rsq_adj=cv_rsq_adj,
mean_cv_rsq_adj = mean(cv_rsq_adj)
))
}
fit_GAM_model = function(formula, data_train){
model = gam(formula, data = data_train)
return(model)
}
k_fold_cv_GAM_model <- function(model_formula, data_train, num_predictors, k=4){
cat("=== Running k_fold Cross Validation --- GAM === \n")
# Create the K-fold partition
folded_data <- k_fold(data_train, k)$.folds
# Initialize a vector to store each fold's rsme
cv_rmse <- numeric(k)
# Initialize a vector to store each fold's Rsq_adj
cv_rsq_adj <- numeric(k)
for (i in 1:k){
# Create the fold's test/train split
temp_train <- data_train[which(folded_data != i),]
temp_test <- data_train[which(folded_data == i),]
# Fit the model and make predictions
temp_model <- fit_GAM_model(model_formula, temp_train)
temp_predictions <- predict(temp_model, newdata = temp_test)
## Calculate error metrics and store them
# Calculate SSE and SST for R^2 adjusted
n_test = nrow(temp_test)
## NOTICE THAT THE NUMBER OF PREDICTORS SHALL BE COMPUTED MANUALLY AND
## AN INPUT
SSE = sum((exp(temp_test$y) - exp(temp_predictions))^2)
SST = sum((mean(exp(temp_test$y)) - exp(temp_test$y))^2)
cv_rsq_adj[i] = 1 - (SSE/(n_test-num_predictors))/(SST/(n_test-1))
# Calculate RMSE
cv_rmse[i] <- sqrt(SSE / n_test)
}
# Return the vector with rmse for each k-fold
return(list(cv_rmse=cv_rmse,
mean_cv_rmse = mean(cv_rmse),
cv_rsq_adj=cv_rsq_adj,
mean_cv_rsq_adj = mean(cv_rsq_adj)
))
}
data <- read_excel("Data/data_train.xlsx")
# radius
# Central point (Puerta del Sol)
center <- c(-3.7038, 40.4168)
# Calculate distances and add a new column
data$radius <- distHaversine(
matrix(c(data$longitud, data$latitud), ncol = 2),
matrix(rep(center, nrow(data)), ncol = 2, byrow = TRUE)
) / 1000  # Convert meters to kilometers
# distrito
data$distrito[data$distrito %in% c("carabanchel", "puente_vallecas", "usera","vallecas","villaverde")] = "south"
data$distrito[data$distrito %in% c("arganzuela", "centro", "chamberi","retiro","salamanca")] = "centro"
data$distrito[data$distrito %in% c("barajas", "chamartin", "fuencarral", "hortaleza", "tetuan")] = "north"
data$distrito[data$distrito %in% c("moncloa","latina")] = "west"
data$distrito[data$distrito %in% c("vallecas","moratalaz","vicalvaro","san_blas","ciudad_lineal")] = "east"
# dorm
data$dorm[data$dorm %in% c("0","1")] = "0&1"
data$dorm[data$dorm %in% c("3","4")] = "3&4"
data$dorm[data$dorm %in% c("5","6","7","8","9","10")] = "5+"
#banos
data$banos[data$banos %in% c("3","4","5","6","7","8")] = "3+"
# type
data$tipo.casa[data$tipo.casa %in% c("Otros","piso")] = "piso"
data$tipo.casa[data$tipo.casa %in% c("chalet","duplex")] = "chalet+duplex"
data$tipo.casa[data$tipo.casa %in% c("atico","estudio")] = "atico+estudio"
# state
data$estado[data$estado %in% c("excelente","nuevo-semin,","reformado")] = "bueno"
data$estado[data$estado %in% c("buen_estado","segunda_mano")] = "medio"
data$estado[data$estado %in% c("a_reformar","reg,-mal")] = "malo"
# normalize latitude and longitude
data$longitud <- (data$longitud - mean(data$longitud))/sd(data$longitud)
data$latitud <- (data$latitud - mean(data$latitud))/sd(data$latitud)
data$train_indices <- NULL
data$log.precio.house.m2 <- log(data$precio.house.m2)
data$precio.house.m2 <- NULL
data$barrio <- NULL
data$cod_barrio <- NULL
data$cod_distrito <- NULL
data$log.sup.util <- log(data$sup.util)
data$sup.util <- NULL
data$sup.const <- NULL
factor_columns <- c("distrito", "dorm", "banos", "tipo.casa", "inter.exter",
"ascensor", "estado", "comercial", "casco.historico", "M.30")
data[factor_columns] <- lapply(data[factor_columns], as.factor)
num_id <- sapply(data, is.numeric)
num_vars <- names(data)[num_id]
num_vars
cat_vars <- names(data)[!num_id]
cat_vars
data_train <- data
data_train$y <- data_train$log.precio.house.m2
data_train$log.precio.house.m2 <- NULL
num_id <- sapply(data_train, is.numeric)
num_vars <- setdiff(names(data_train)[num_id],"y")
predictors <- c("ref.hip.zona", "antig", "Poca_limp", "PM10", "Pobl.0_14_div_Poblac.Total" ,   "PoblJubilada_div_Poblac.Total", "Inmigrantes.porc", "Pocas_zonas")
cat_vars = factor_columns
# Create a fucntion to automatically normalize the numerical vars
normalize = function(row){
row = (row - mean(row))/sd(row)
return(row)
}
data_train[setdiff(num_vars, "radius")] = apply(data_train[setdiff(num_vars, "radius")], 2, normalize)
### ALL MODEL
num_id <- sapply(data_train, is.numeric)
num_vars <- setdiff(names(data_train)[num_id], "y")
num_vars
cat_vars <- names(data_train)[!num_id]
cat_vars
total_lm_formula <- as.formula(
paste("y ~", "(", paste(num_vars, collapse = " + "), ")", "*", "(", paste(cat_vars, collapse = " + "), ")" )
)
total_lm_model = lm(total_lm_formula,data = data_train)
summary(total_lm_model)
k_fold_cv_linear_model(total_lm_formula, data_train)
### AIC
total_lm_AIC <- stepAIC(total_lm_model, direction = 'both')
summary(total_lm_AIC)
save(total_lm_AIC, file = "Modelos Nico 2/total_lm_AIC.RData")
load("Modelos Nico 2/total_lm_AIC.RData")
total_AIC_predictors <- labels(terms(total_lm_AIC))
total_AIC_predictors
summary(total_lm_model)
summary(total_lm_AIC)
total_AIC_predictors <- labels(terms(total_lm_AIC))
total_lm_AIC_formula <- as.formula(
paste("y ~", paste(total_AIC_predictors, collapse = " + "))
)
k_fold_cv_linear_model(total_lm_AIC_formula, data_train)
